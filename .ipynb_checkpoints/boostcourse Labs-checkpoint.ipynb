{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [부스트코드] 텐서플로우로 시작하는 딥러닝 기초\n",
    "\n",
    "## Lab 02 Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "x_data = [1,2,3,4,5]\n",
    "y_data = [1,2,3,4,5]\n",
    "\n",
    "#W, b initialize\n",
    "W = tf.Variable(2.9)\n",
    "b = tf.Variable(0.5)\n",
    "\n",
    "#learning_rate initialize\n",
    "#기울기를 얼마만큼 반영할 것인가를 결정하는 값\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    i\t     W\t\tb\tcost\n",
      "    0|    2.4520|     0.376| 45.660004\n",
      "    1|    2.1100|    0.2814| 26.608438\n",
      "    4|    1.4975|     0.112|  5.265920\n",
      "    5|    1.3813|   0.07987|  3.068760\n",
      "   16|    1.0256|  -0.01771|  0.008174\n",
      "   17|    1.0210|  -0.01889|  0.004804\n",
      "   20|    1.0128|  -0.02091|  0.001026\n",
      "   21|    1.0113|  -0.02127|  0.000637\n",
      "   32|    1.0063|  -0.02175|  0.000089\n",
      "   33|    1.0062|  -0.02169|  0.000087\n",
      "   36|    1.0060|   -0.0215|  0.000085\n",
      "   37|    1.0060|  -0.02143|  0.000084\n",
      "   48|    1.0057|  -0.02067|  0.000078\n",
      "   49|    1.0057|   -0.0206|  0.000078\n",
      "   52|    1.0056|  -0.02039|  0.000076\n",
      "   53|    1.0056|  -0.02032|  0.000076\n",
      "   64|    1.0054|  -0.01958|  0.000070\n",
      "   65|    1.0054|  -0.01951|  0.000070\n",
      "   68|    1.0053|  -0.01931|  0.000068\n",
      "   69|    1.0053|  -0.01925|  0.000068\n",
      "   80|    1.0051|  -0.01854|  0.000063\n",
      "   81|    1.0051|  -0.01848|  0.000063\n",
      "   84|    1.0051|  -0.01829|  0.000061\n",
      "   85|    1.0051|  -0.01823|  0.000061\n",
      "   96|    1.0049|  -0.01757|  0.000057\n",
      "   97|    1.0048|  -0.01751|  0.000056\n",
      "  100|    1.0048|  -0.01733|  0.000055\n"
     ]
    }
   ],
   "source": [
    "#Parameter(W, b) Update\n",
    "print(\"    i\\t     W\\t\\tb\\tcost\")\n",
    "for i in range(100+1):\n",
    "    # Gradient descent \n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W*x_data +b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "    W.assign_sub(learning_rate*W_grad)\n",
    "    b.assign_sub(learning_rate*b_grad)\n",
    "    if i&10 == 0:\n",
    "        print(\"{:5}|{:10.4f}|{:10.4}|{:10.6f}\".format(i, W.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 03 Linear Regression and How to minimize cost\n",
    "## Cost function in pure Python - 비용 함수 구현하기\n",
    "\n",
    "### 비용 = 편차 제곱의 평균\n",
    "### 예측값 (=가정): $H(x) = Wx$\n",
    "### 비용함수: $cost(W) = \\frac{1}{m} \\sum_{i=1}^m (W x_i - y_i)^2$ where m = len(W) = 데이터의 개수\n",
    "### 가정을 함수에 대입하면, $cost(W) = \\frac{1}{m} \\sum_{i=1}^m (H(x) - y_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "def cost_func(W, X, Y):\n",
    "    c = 0\n",
    "    for i in range(len(X)):\n",
    "        c += (W * X[i] - Y[i]) ** 2\n",
    "    return c/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "for feed_W in np.linspace(-3, 5, num=15):\n",
    "    curr_cost = cost_func(feed_W, X, Y)\n",
    "    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow를 이용한 비용함수의 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_func_tf(W, X, Y):\n",
    "    hypothesis = X * W\n",
    "    return tf.reduce_mean(tr.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "W_values = np.linspace(-3, 5, num=15)\n",
    "cost_values = []\n",
    "\n",
    "for feed_W in W_values:\n",
    "    curr_cost = cost_func(feed_W, X, Y)\n",
    "    cost_values.append(curr_cost)\n",
    "    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow를 이용한 gradient 함수의 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent: $W = W - \\alpha\\frac{1}{m} \\sum_{i=1}^m (W(x_i) - y_i)x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0) #for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1., 2., 3., 4.]\n",
    "y_data = [1., 3., 5., 7.]\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1], -100., 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
