{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12-0 RNN Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1: 특정 셀을 선언하고 이를 루프함.\n",
    "# 다른 방식을 적용시킬 수 있는 방법\n",
    "cell = layers.SimpleRNNCell(units=hidden_size)\n",
    "rnn = layers.RNN(cell, return_sequences=True, return_state=True)\n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "# 방법2: cell ,rnn 부분 통합\n",
    "rnn = layers.SimpleRNN(units=hidden_size, return_sequence=True, return_state=True)\n",
    "outputs, states = rnn(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "h = [1,0,0,0]\n",
    "e = [0,1,0,0]\n",
    "l = [0,0,1,0]\n",
    "l = [0,0,1,0]\n",
    "o = [0,0,0,1]\n",
    "\n",
    "x_data = np.array([[h]], dtype=np.float32)\n",
    "hidden_size = 2\n",
    "\n",
    "# tensorflow에서 RNN을 이용할 때, RNN의 input:(batch_size, sequence_length, input_dimension)\n",
    "\n",
    "cell = layers.SimpleRNNCell(units=hidden_size)\n",
    "rnn = layers.RNN(cell, return_sequences=True, return_state=True)\n",
    "outputs, states = rnn(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data = [[[1. 0. 0. 0.]]], shape = (1, 1, 4)\n",
      "outputs = [[[0.01397352 0.58250177]]], shape = (1, 1, 2)\n",
      "states = [[0.01397352 0.58250177]], shape = (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print('x_data = {}, shape = {}'.format(x_data, x_data.shape))\n",
    "print('outputs = {}, shape = {}'.format(outputs, outputs.shape)) # 전체 sequence에 해당하는 hidden state 가짐.\n",
    "print('states = {}, shape = {}'.format(states, states.shape)) # sequence의 마지막 hidden state 값만 가짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfolding to n sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data = [[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]], shape = (1, 5, 4) \n",
      "\n",
      "outputs = [[[ 0.53826106 -0.64724684]\n",
      "  [ 0.7226483   0.47216213]\n",
      "  [ 0.17025973 -0.5796663 ]\n",
      "  [-0.68650365 -0.04160718]\n",
      "  [ 0.04732385  0.3608838 ]]], shape = (1, 5, 2) \n",
      "\n",
      "states = [[0.04732385 0.3608838 ]], shape = (1, 2)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[h,e,l,l,o]], dtype=np.float32)\n",
    "\n",
    "hidden_size = 2\n",
    "rnn = layers.SimpleRNN(units=hidden_size, return_sequences=True, return_state=True)\n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print('x_data = {}, shape = {} \\n'.format(x_data, x_data.shape))\n",
    "print('outputs = {}, shape = {} \\n'.format(outputs, outputs.shape)) # 전체 sequence에 해당하는 hidden state 가짐.\n",
    "print('states = {}, shape = {}'.format(states, states.shape)) # sequence의 마지막 hidden state 값만 가짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data = [[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]]], shape = (3, 5, 4) \n",
      "\n",
      "outputs = [[[-0.51382005 -0.1230486 ]\n",
      "  [ 0.67331725  0.682556  ]\n",
      "  [-0.6701331  -0.8969959 ]\n",
      "  [ 0.7751847  -0.46881172]\n",
      "  [ 0.8386391  -0.9121355 ]]\n",
      "\n",
      " [[ 0.52256954  0.34665102]\n",
      "  [ 0.4463591  -0.8034484 ]\n",
      "  [ 0.59646136 -0.9177119 ]\n",
      "  [ 0.6438261  -0.9409788 ]\n",
      "  [ 0.6507167  -0.94659287]]\n",
      "\n",
      " [[ 0.00706756 -0.7427566 ]\n",
      "  [ 0.6222476  -0.811965  ]\n",
      "  [ 0.8421848  -0.40473554]\n",
      "  [ 0.6538544  -0.5009945 ]\n",
      "  [ 0.3326909  -0.93633157]]], shape = (3, 5, 2) \n",
      "\n",
      "states = [[ 0.8386391  -0.9121355 ]\n",
      " [ 0.6507167  -0.94659287]\n",
      " [ 0.3326909  -0.93633157]], shape = (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# sequence = 5\n",
    "x_data = np.array([[h,e,l,l,o],\n",
    "                  [e,o,l,l,l],\n",
    "                  [l,l,e,e,l]], dtype=np.float32)\n",
    "\n",
    "hidden_size = 2\n",
    "rnn = layers.SimpleRNN(units=hidden_size, return_sequences=True, return_state=True)\n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print('x_data = {}, shape = {} \\n'.format(x_data, x_data.shape))\n",
    "print('outputs = {}, shape = {} \\n'.format(outputs, outputs.shape)) # 전체 sequence에 해당하는 hidden state 가짐.\n",
    "print('states = {}, shape = {}'.format(states, states.shape)) # sequence의 마지막 hidden state 값만 가짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12-1 Many to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word sentiment classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['good', 'bad', 'worse', 'so good']\n",
    "y_data = [1,0,0,1] #1은 긍정 0은 부정\n",
    "\n",
    "#creating a token dictionary\n",
    "char_set = ['<pad>'] + sorted(list(set(''.join(words)))) \n",
    "# word를 char의 sequence로 간주했을 때, 각각의 sequence의 길이가 다르기 때문에 <pad> 추가.\n",
    "idx2char = {idx:char for idx, char in enumerate(char_set)}\n",
    "char2idx = {char:idx for idx, char in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', ' ', 'a', 'b', 'd', 'e', 'g', 'o', 'r', 's', 'w']\n",
      "{0: '<pad>', 1: ' ', 2: 'a', 3: 'b', 4: 'd', 5: 'e', 6: 'g', 7: 'o', 8: 'r', 9: 's', 10: 'w'}\n",
      "{'<pad>': 0, ' ': 1, 'a': 2, 'b': 3, 'd': 4, 'e': 5, 'g': 6, 'o': 7, 'r': 8, 's': 9, 'w': 10}\n"
     ]
    }
   ],
   "source": [
    "print(char_set)\n",
    "print(idx2char)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]\n",
      "[4, 3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "# converting sequence of tokens to sequence of indices\n",
    "x_data = list(map(lambda word:[char2idx.get(char) for char in word], words))\n",
    "x_data_len = list(map(lambda word: len(word), x_data))\n",
    "\n",
    "print(x_data)\n",
    "print(x_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7  7  4  0  0  0  0  0  0]\n",
      " [ 3  2  4  0  0  0  0  0  0  0]\n",
      " [10  7  8  9  5  0  0  0  0  0]\n",
      " [ 9  7  1  6  7  7  4  0  0  0]]\n",
      "[4, 3, 5, 7]\n",
      "[1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# padding the sequence of indices\n",
    "max_sequence = 10\n",
    "x_data = keras.preprocessing.sequence.pad_sequences(sequences = x_data, maxlen = max_sequence, padding='post', truncating='post')\n",
    "\n",
    "print(x_data)\n",
    "print(x_data_len)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating simple rnn for \"many to one\" classification\n",
    "input_dim = len(char2idx)\n",
    "output_dim = len(char2idx)\n",
    "one_hot = np.eye(len(char2idx))\n",
    "hidden_size = 10\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 11)            121       \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 10)                220       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 363\n",
      "Trainable params: 242\n",
      "Non-trainable params: 121\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
    "                          trainable=False, mask_zero=True, input_length=max_sequence,\n",
    "                          embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_size))\n",
    "model.add(layers.Dense(units=num_classes))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 10), (None,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# creating Loss junction\n",
    "def loss_fn(model, x, y):\n",
    "    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y_true=y, y_pred=model(x), from_logits=True))\n",
    "\n",
    "#creating an optimizer\n",
    "lr = .01\n",
    "epochs = 30\n",
    "batch_size = 2\n",
    "opt = tf.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "# generating data pipeline\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
    "tr_dataset = tr_dataset.batch(batch_size =batch_size)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =   5, tr_loss = 0.140\n",
      "epoch =  10, tr_loss = 0.026\n",
      "epoch =  15, tr_loss = 0.011\n",
      "epoch =  20, tr_loss = 0.006\n",
      "epoch =  25, tr_loss = 0.004\n",
      "epoch =  30, tr_loss = 0.003\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch = {:3}, tr_loss = {:.3f}'.format(epoch+1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 100.00%\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1)\n",
    "print('acc : {:.2%}'.format(np.mean(yhat == y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2527d8af4f0>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
